{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the jovian Python library\n",
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations\n",
    "## List of few interesting yet useful functions used in PyTorch\n",
    "### PyTorch is a library based on Python that is used to optimize tensor manipulations. Few advantages to use PyTorch include its array of packages used for deep learning, python support and dynamic computation graphs.\n",
    "##### 1. torch.reshape()\n",
    "##### 2. torch.unsqueeze()\n",
    "##### 3. torch.mm()\n",
    "##### 4. torch.mul()\n",
    "##### 5. torch.cross()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"Type:       {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values:\\n {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion 1 - torch.reshape(input, shape) -> tensor\n",
    "\n",
    "reshape() was introduced in version 0.4 . It returns a tensor with the\n",
    "same data as input but with a specified shape. When we use torch.reshape(),\n",
    "the new tensor could be a view of the orignal tensor or it could be a new tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4])\n",
      "Values:\n",
      " tensor([[0.3639, 0.2020, 0.3837, 0.4622],\n",
      "        [0.8334, 0.9769, 0.1666, 0.9551],\n",
      "        [0.5527, 0.0371, 0.2782, 0.1400]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3639, 0.2020],\n",
       "        [0.3837, 0.4622],\n",
       "        [0.8334, 0.9769],\n",
       "        [0.1666, 0.9551],\n",
       "        [0.5527, 0.0371],\n",
       "        [0.2782, 0.1400]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: working\n",
    "a = torch.rand(3, 4)\n",
    "describe(a)\n",
    "a.reshape(6, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, it can be noticed that we can specify the row x column shape of our want.\n",
    "\n",
    "\n",
    "It should be noted that product of all the shapes need to be same as total number of elements in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3639, 0.2020, 0.3837, 0.4622]],\n",
       "\n",
       "        [[0.8334, 0.9769, 0.1666, 0.9551]],\n",
       "\n",
       "        [[0.5527, 0.0371, 0.2782, 0.1400]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: working\n",
    "a.reshape(3, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, the rank of the tensor is increased to 4. There are 3 channels, where each row has 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 2, 2]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-633a53751a23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3: breaking point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[4, 2, 2]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "# Example 3: breaking point\n",
    "a.reshape(4, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier that the product of shapes must be equal to the number of elements in the tensor, otherwise, we will encounter a runtime error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - torch.unsqeeze(input, dim) -> tensor\n",
    "unsqueeze() returns a tensor after adding a dimension of length one at a specified position.\n",
    "It shares the same data as the orignal tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values:\n",
      " tensor([0.3595, 0.4733, 0.5840])\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3])\n",
      "Values:\n",
      " tensor([[0.3595, 0.4733, 0.5840]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1: working\n",
    "a = torch.rand(3)\n",
    "describe(a)\n",
    "describe(torch.unsqueeze(a, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we have added a new dimension at position zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 1])\n",
      "Values:\n",
      " tensor([[0.3595],\n",
      "        [0.4733],\n",
      "        [0.5840]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.unsqueeze(a, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example 2, a new dimension is added at position 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[0.7627, 0.3160, 0.7986],\n",
      "        [0.4636, 0.0492, 0.1258]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-3, 2], but got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-45f455684f37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
     ]
    }
   ],
   "source": [
    "b = torch.rand(2,3)\n",
    "describe(b)\n",
    "describe(torch.unsqueeze(b, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the tensor in b is 2 dimensional with the shape of ([2, 2]). So if you add an additional dimension at position 0, \n",
    "the resultant shape will be (1, 2, 2), and for adding a dimension at 1 and 2 position, the resulting shape will\n",
    "be ([2,1,2]), ([2,2,1]) respectively. In example 3, an IndexError occurs because dimension is out of range. \n",
    "The range is calculated by [-input.dim() - 1, input.dim() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - torch.mm(input, other) -> tensor\n",
    "The mm() preforms matrix multiplication of two matrices.\n",
    "The matrix1 tensor is (n, m) shape, matrix2 is of (m, p) shape and output tensor will be (n, p) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 4])\n",
      "Values:\n",
      " tensor([[0.7245, 0.0418, 0.7495, 0.5198],\n",
      "        [0.6651, 0.8343, 0.5346, 0.5054]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values:\n",
      " tensor([[0.6612, 0.0372, 0.8452],\n",
      "        [0.8726, 0.9716, 0.2240],\n",
      "        [0.4842, 0.4053, 0.0668],\n",
      "        [0.1179, 0.6183, 0.3120]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[0.9397, 0.6927, 0.8340],\n",
      "        [1.4862, 1.3645, 0.9424]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1: working\n",
    "a = torch.rand(2, 4)\n",
    "b = torch.rand(4, 3)\n",
    "describe(a)\n",
    "print(\"====================================\")\n",
    "describe(b)\n",
    "print(\"====================================\")\n",
    "describe(torch.mm(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example, two tensors a, b with the shape ([2, 4]), ([4, 3]) are created respectively. mm() multiplies two matrices and returns tensor with the shape of ([2, 3])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 4])\n",
      "Values:\n",
      " tensor([[0.9123, 0.6377, 0.2002, 0.7896]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([4, 2])\n",
      "Values:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values:\n",
      " tensor([[2.5398, 2.5398]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2: working\n",
    "a = torch.rand(1, 4)\n",
    "describe(a)\n",
    "print(\"====================================\")\n",
    "b = torch.ones(4, 2)\n",
    "describe(b)\n",
    "print(\"====================================\")\n",
    "describe(torch.mm(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example is similar to first example, where the resulting matrix has a shape of ([1, 2])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 1D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:131",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e3db12e5b168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 1D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:131"
     ]
    }
   ],
   "source": [
    "# Example 3: breaking point\n",
    "x = torch.rand(0)\n",
    "y = torch.rand(2, 3)\n",
    "describe(torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix multiplication using mm() in pytorch does'nt work on matrices that are not bradcastable. \n",
    "In third example, a and b are not broadcastable, because a does not have atleast 1 dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - torch.mul(input, other) -> tensor\n",
    "The function torch.mul() performs the element-wise multiplication of two tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 2, 3])\n",
      "Values:\n",
      " tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.]]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3])\n",
      "Values:\n",
      " tensor([[0.5282, 0.2708, 0.5079]])\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 2, 3])\n",
      "Values:\n",
      " tensor([[[0.0000, 0.2708, 1.0159],\n",
      "         [1.5846, 1.0830, 2.5397]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[ 0., 1., 2.],\n",
    "                   [ 3., 4., 5.]]])\n",
    "describe(a)\n",
    "print(\"====================================\")\n",
    "b = torch.rand(1, 3)\n",
    "describe(b)\n",
    "print(\"====================================\")\n",
    "describe(torch.mul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the aforementioned example, we perform element wise matrix multiplication between tensors a , b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[0.8370, 0.7273, 0.2861],\n",
      "        [0.7734, 0.7017, 0.4191]])\n",
      "====================================\n",
      "====================================\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[83.7022, 72.7301, 28.6087],\n",
      "        [77.3449, 70.1695, 41.9115]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "describe(a)\n",
    "print(\"====================================\")\n",
    "b = 100\n",
    "print(\"====================================\")\n",
    "describe(torch.mul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As show in the second example, elementwise multiplication is performed where, matrix a is a FloatTensor, it could also be a DoubleTensor and the matrix b is an integer, it can also be any real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2, 3])\n",
      "Values:\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "====================================\n",
      "Type:       torch.LongTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values:\n",
      " tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]])\n",
      "====================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3a5b3672e7e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"====================================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Example 3: Breaking point\n",
    "a = torch.tensor([[[1, 2, 3],\n",
    "  [4, 5, 6]]])\n",
    "describe(a)\n",
    "print(\"====================================\")\n",
    "b = torch.tensor([[1, 1, 1],\n",
    " [2, 2, 2],\n",
    " [3, 3, 3]])\n",
    "describe(b)\n",
    "print(\"====================================\")\n",
    "describe(torch.mul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the third example cell, we encounter an error because the dimensions of two matrices must be equal i.e. broadcastable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - torch.cross(matrix1, matrix2, dim = -1, out) -> tensor\n",
    "cross() returns cross product of vectors in dimension of matrix1 and matrix2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-6., 12., -6.],\n",
       "        [-6., 12., -6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: Working\n",
    "a = torch.tensor([[0. , 1. , 2.],\n",
    "                 [3. , 4. , 5.]])\n",
    "b = torch.tensor([[6., 7. , 8.],\n",
    "                  [9., 10. , 11.]])\n",
    "describe(a)\n",
    "describe(b)\n",
    "torch.cross(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, cross() creates a tensor with the result of cross product between two matrices a and b\n",
    "with the shapes of ([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values:\n",
      " tensor([[ 0.2770, -0.4374,  0.4432],\n",
      "        [-0.0979,  0.0179,  0.0294]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Working\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(2, 3)\n",
    "describe(torch.cross(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to example 1, cross product is performed on two matrices with random real numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 4])\n",
      "Values:\n",
      " tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]])\n",
      "Type:       torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 4])\n",
      "Values:\n",
      " tensor([[ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "no dimension of size 3 in input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3d3f7e03ff32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: no dimension of size 3 in input"
     ]
    }
   ],
   "source": [
    "# Example 3: Breaking point\n",
    "a = torch.tensor([[0. , 1. , 2., 3.],\n",
    "                 [4. , 5. , 6., 7.]])\n",
    "b = torch.tensor([[8., 9. , 10. , 11.],\n",
    "                  [12., 13. , 14. , 15.]])\n",
    "describe(a)\n",
    "describe(b)\n",
    "describe(torch.cross(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We come accross RuntimeError in third example, this is due to the reason that the dimensions of the a and b tensors do'nt match. It is important to note that matrix1 and matrix2 must have the same size, and the size of their dimension\n",
    "must be 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we explored 5 of many interesting and usefull functions to work with tensors using pytorch. We understood the defination and working of the functions with working examples and also came accross errors some examples  because it is also important to know when those functions would'nt work. \n",
    "\n",
    "Thank You very much!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Links\n",
    "1. Official documentation for torch.Tensor: https://pytorch.org/docs/stable/tensors.html\n",
    "2. Tensors For Deep Learning With PyTorch: https://deeplizard.com/learn/video/fCVuiW9AFzY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\n",
      "[jovian] Updating notebook \"harsh-hr305/pytorch-assignment\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harsh-hr305/pytorch-assignment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/harsh-hr305/pytorch-assignment'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
